{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inz_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kfk7Z9wLrwy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wczytywanie danych"
      ],
      "metadata": {
        "id": "nVwolw69iuc5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyUN07MxEO5y"
      },
      "source": [
        "data=pd.read_csv(r'list_v7_final.csv')\n",
        "data.drop_duplicates(subset=['Game_name'],inplace=True)\n",
        "data.dropna(axis=0,inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Czyszczenie danych"
      ],
      "metadata": {
        "id": "Bjvbcx7-izCZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS5IeO_cL-Ox"
      },
      "source": [
        "stop_words = set(pd.read_csv(r'polish_stopwords.txt')['a']) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)  \n",
        "    newString = re.sub(r\"'s\\b\",'',newString)\n",
        "    newString = re.sub(\"[^AaĄąBbCcĆćDdEeĘęFfGgHhIiJjKkLlŁłMmNnŃńOoÓóPpQqRrSsŚśTtUuWwVvXxYyZzŹźŻż]\", \" \", newString) \n",
        "\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if w not in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 \n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amJgjIa5jesK"
      },
      "source": [
        "cleaned_text = []\n",
        "cleaned_summary = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    cleaned_text.append(text_cleaner(data['Opis'][i],0)) \n",
        "    cleaned_summary.append(text_cleaner(data['Short_text'][i],1))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ocena długości tekstów, celem eliminacji nielicznych długich\n",
        "Pozwala to na ograniczenie rozmiaru modelu"
      ],
      "metadata": {
        "id": "S3QuFTpEjtR8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxvBqTz6k-Bz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "acecc3d8-9c20-434d-e050-51278cf19758"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyliczanie wskaźnika pokrycia zboioru danych dla zadanej długości maksymalnej, oraz ograniczenie jego wielkości na tej podstawie:"
      ],
      "metadata": {
        "id": "M_7d0d2Ax9cn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiEVYgd7k_1G"
      },
      "source": [
        "max_text_len=300\n",
        "\n",
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=max_text_len):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_summary_len=60\n",
        "\n",
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=max_summary_len):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "metadata": {
        "id": "gveSEDhBXoOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxmcRuL6lHSO"
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizacja wyrazów z tekstów z bazy danych"
      ],
      "metadata": {
        "id": "LWKRspBa5vpB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL8k9TpJlWOi"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx1hnjxplwxm"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt += 1\n",
        "    tot_freq += value\n",
        "    if(value<thresh):\n",
        "        cnt += 1\n",
        "        freq += value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHt00NQam-Oy"
      },
      "source": [
        "import pickle\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "x_voc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te2Afe_voOO_"
      },
      "source": [
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLrFVuuJoWxG"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt += 1\n",
        "    tot_freq += value\n",
        "    if(value<thresh):\n",
        "        cnt += 1\n",
        "        freq += value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlEwEttCocvm"
      },
      "source": [
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "\n",
        "y_tokenizer.word_counts['sostok'],len(y_tr)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfoVWpTyohpO"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgZX-Ci3oqf6"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvrJ67wwqi96"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 200\n",
        "embedding_dim = 200\n",
        "\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n",
        "\n",
        "encoder_lstm4=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3)\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs1,decoder_fwd_state1, decoder_back_state1 = decoder_lstm1(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state2, decoder_back_state2 = decoder_lstm2(decoder_outputs1)\n",
        "\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56M8EROfteAU"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=25,callbacks=[es],batch_size=200, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq4y-9zEwJ1V"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.grid()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeuUGJ5M1SNh"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('reverse_target_word_index.npy', reverse_target_word_index) \n",
        "np.save('reverse_source_word_index.npy', reverse_source_word_index) \n",
        "np.save('target_word_index.npy', target_word_index) "
      ],
      "metadata": {
        "id": "ls4Gfuy2gKGG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpNs-OPa1TLw"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "encoder_model.summary()\n",
        "#encoder_model.save('/content/drive/MyDrive/models/my_encoder')\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "\n",
        "d_decoder_outputs1, d_state_h1, d_state_c1 = decoder_lstm1(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "d_decoder_outputs, d_state_h, d_state_c = decoder_lstm2(d_decoder_outputs1)\n",
        "\n",
        "\n",
        "d_decoder_outputs = decoder_dense(d_decoder_outputs) \n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "    [d_decoder_outputs] + [d_state_h, d_state_c])\n",
        "\n",
        "decoder_model.summary()\n",
        "\n",
        "#decoder_model.save('/content/drive/MyDrive/models/my_decoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJNZetHhEFyN"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_8YcbHQExI1"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUSBY5IYEzXB"
      },
      "source": [
        "for i in range(10):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}